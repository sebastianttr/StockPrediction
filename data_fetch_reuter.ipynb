{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reuters Data fetch and save\n",
    "\n",
    "This notebook downloads all the data from the reuters about a specific topic and saves it to the database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0dcebd334270cc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import html5lib\n",
    "from io import StringIO, BytesIO\n",
    "import lxml.html\n",
    "from lxml import html\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import clear_output, display\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import requests\n",
    "import math\n",
    "import ray\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T19:01:22.606759Z",
     "start_time": "2024-03-12T19:01:22.600070Z"
    }
   },
   "id": "4194653680e1e8be",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_PAGE_SIZE = 50\n",
    "REUTERS_QUERY_URL = 'https://www.reuters.com/pf/api/v3/content/fetch/articles-by-search-v2'\n",
    "PAGES_REQUESTS_SIZE = 5    # the amount of request ran in parallel to get pages faster, 10 pages loaded at the same time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T19:14:33.945747Z",
     "start_time": "2024-03-12T19:14:33.940979Z"
    }
   },
   "id": "c57473e637439ebb",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 20:50:07,459\tINFO worker.py:1558 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query size is  5117\n",
      "total_page_size is  103\n",
      "pages_range is  21\n"
     ]
    },
    {
     "data": {
      "text/plain": "IntProgress(value=0, max=21)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af4ce8074ae44f86afb3db8c68933dcc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page 1 / 2150\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 2 / 21300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 3 / 21550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 4 / 21800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "49\n",
      "50\n",
      "49\n",
      "50\n",
      "50\n",
      "Loading page 5 / 211050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 6 / 211300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 7 / 211550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 8 / 211800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 9 / 212050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "50\n",
      "49\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 10 / 212300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 11 / 212550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 12 / 212800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 13 / 213050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "49\n",
      "Loading page 14 / 213300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Loading page 15 / 213550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "50\n",
      "50\n",
      "49\n",
      "50\n",
      "50\n",
      "Loading page 16 / 213800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "50\n",
      "48\n",
      "50\n",
      "49\n",
      "50\n",
      "Loading page 17 / 214050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "50\n",
      "48\n",
      "48\n",
      "50\n",
      "49\n",
      "Loading page 18 / 214300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "50\n",
      "49\n",
      "50\n",
      "49\n",
      "50\n",
      "Loading page 19 / 214550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "48\n",
      "50\n",
      "50\n",
      "49\n",
      "50\n",
      "Loading page 20 / 214800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "5000\n",
      "50\n",
      "50\n",
      "50\n",
      "49\n",
      "49\n",
      "Loading page 21 / 215050\n",
      "5100\n",
      "5150\n",
      "5200\n",
      "5250\n",
      "49\n",
      "17\n",
      "Error getting articles! {'statusCode': 400, 'result': None, '_id': 'c95c5ade6a77bb806de112e589fa2540cfe383543b2c63d08c9c7a1ff3cdc43f'}\n",
      "Error getting articles! {'statusCode': 400, 'result': None, '_id': 'c95c5ade6a77bb806de112e589fa2540cfe383543b2c63d08c9c7a1ff3cdc43f'}\n",
      "Error getting articles! {'statusCode': 400, 'result': None, '_id': 'c95c5ade6a77bb806de112e589fa2540cfe383543b2c63d08c9c7a1ff3cdc43f'}\n",
      "\n",
      " Result Size:  5046\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "'''\n",
    "This functions queries reuters and gets the first few articles\n",
    "This query contains the \n",
    "'''\n",
    "\n",
    "num_cpus = 4\n",
    "    \n",
    "ray.init(ignore_reinit_error=True, num_cpus=num_cpus)\n",
    "\n",
    "def get_query_param(keyword, offset):\n",
    "    print(offset)\n",
    "    \n",
    "    return {\n",
    "        \"query\": '{\"keyword\":\"%s\",\"offset\":%d,\"orderby\":\"display_date:desc\",\"size\":%d,\"website\":\"reuters\"}' % (keyword, offset, MAX_PAGE_SIZE),\n",
    "        \"d\": 179,\n",
    "        \"_website\": \"reuters\"\n",
    "    }\n",
    "\n",
    "def append_articles(articles_list, query_list):\n",
    "    requests_keys = [\"id\",\"canonical_url\",\"title\",\"published_time\"]\n",
    "\n",
    "    for query_articles in query_list:\n",
    "        articles_list.append({key: query_articles[key] for key in requests_keys})\n",
    "\n",
    "    return articles_list\n",
    "\n",
    "# resources = {\"requests_resource\": 1}, num_cpus=num_cpus\n",
    "@ray.remote\n",
    "def try_request(url, headers, params):\n",
    "        \n",
    "    response_page = requests.request(\"GET\", url, headers=headers, params=params, timeout=30)\n",
    "    try:\n",
    "        json_response = response_page.json()\n",
    "                \n",
    "        if response_page.status_code > 300:\n",
    "            print(\"Status code error: \" + str(response_page.status_code))\n",
    "            return False, params\n",
    "\n",
    "        return True, json_response\n",
    "    except requests.exceptions.JSONDecodeError as e:\n",
    "        print(f\"Bad Request: GET {url} \\n Status Code: {response_page.status_code} | Error : {e}\")\n",
    "        return False, params\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Timed out\")\n",
    "        return False, params\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Bad Request: GET {url} \\n\")\n",
    "        return False, params\n",
    "\n",
    "def query_reuters_news_meta(keyword):\n",
    "\n",
    "    # full query list\n",
    "    query_list = []\n",
    "\n",
    "    # build header. has just the cookie\n",
    "    headers = {\n",
    "        'Cookie': 'datadome=5DoGfdp_v7Y64hF3yeg8zmFRJvUZ_kY9APCBHhhY8Q5HnPWurio8XinFbT~guJr5RlIj0N41S2aQQNBEiMf05rg2Mb3BBC9zMM7Akw1aS8O9285Y~CC1YlyPQoYKfgLi; reuters-geo={\"country\":\"AT\", \"region\":\"-\"}'\n",
    "    }\n",
    "\n",
    "    # build the query params. \"query\" property must be a string of JSON, not an actual dict. must contain keyword and max page size\n",
    "    params = {\n",
    "        \"query\": '{\"keyword\":\"%s\",\"offset\":0,\"orderby\":\"display_date:desc\",\"size\":%d,\"website\":\"reuters\"}' % (keyword,MAX_PAGE_SIZE),\n",
    "        \"d\": 179,\n",
    "        \"_website\": \"reuters\"\n",
    "    }\n",
    "    \n",
    "    # make the first request\n",
    "    response_first = requests.request(\"GET\", REUTERS_QUERY_URL, headers=headers, params=params).json()\n",
    "    \n",
    "    # query_list.append({key: article[key] for key in requests_keys})\n",
    "\n",
    "    # print(\"Request done\")\n",
    "    # check if the request was valid by the given status code, else raise exception\n",
    "    if response_first['statusCode'] == 400:\n",
    "        raise Exception(f\"Bad Request: Query size of {MAX_PAGE_SIZE} is bigger than 100 with is not valid.\" )\n",
    "\n",
    "    # get pegination data and load all pages\n",
    "    query_result_total_size = response_first[\"result\"][\"pagination\"][\"total_size\"] \n",
    "    print(\"Query size is \", query_result_total_size)\n",
    "    \n",
    "    total_page_size = math.ceil(query_result_total_size / MAX_PAGE_SIZE)\n",
    "    \n",
    "    print(\"total_page_size is \", total_page_size)\n",
    "\n",
    "    pages_range = math.ceil(total_page_size / PAGES_REQUESTS_SIZE)\n",
    "\n",
    "    print(\"pages_range is \", pages_range)\n",
    "    \n",
    "    f = IntProgress(min=0, max=pages_range) # instantiate the bar\n",
    "\n",
    "    # add first response to query list\n",
    "    # query_list = append_articles(query_list, response_first[\"result\"][\"articles\"])\n",
    "\n",
    "    display(f) # display the bar\n",
    "    f.value += 1\n",
    "\n",
    "    #start at two and get all the messages available\n",
    "    # we will load 10 pages in parallel and  until we have all the pages.\n",
    "    last_offset = 0\n",
    "    \n",
    "    for i in range(pages_range):\n",
    "        print(\"\\rLoading page %d / %d\" % (i+1, pages_range), end=\"\")\n",
    "\n",
    "        tasks = []\n",
    "        for _ in range(PAGES_REQUESTS_SIZE):\n",
    "            offset = MAX_PAGE_SIZE + last_offset\n",
    "            tasks.append(\n",
    "                try_request.remote(\n",
    "                    REUTERS_QUERY_URL, \n",
    "                    params = get_query_param(keyword=keyword, offset=offset), \n",
    "                    headers = headers)\n",
    "            )\n",
    "            last_offset = offset\n",
    "        \n",
    "        results_list = ray.get(tasks)\n",
    "        \n",
    "        for (request_ok, json_parsed) in results_list:\n",
    "            if request_ok:\n",
    "                try:\n",
    "                    print(len(json_parsed[\"result\"][\"articles\"]))\n",
    "                    query_list = append_articles(query_list, json_parsed[\"result\"][\"articles\"])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error getting articles! {str(json_parsed)}\")\n",
    "                    pass\n",
    "            else:\n",
    "                print(f\"Error at task {last_offset}\")\n",
    "\n",
    "        f.value += 1\n",
    "\n",
    "    return query_list\n",
    "\n",
    "meta_list = query_reuters_news_meta(\"Tesla\")\n",
    "print(\"\\n Result Size: \", len(meta_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T19:52:19.386657Z",
     "start_time": "2024-03-12T19:50:07.460530Z"
    }
   },
   "id": "1c222d877add03eb",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 39\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m article \u001B[38;5;129;01min\u001B[39;00m articles:\n\u001B[1;32m     37\u001B[0m         load_single_article_text(article[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcanonical_url\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m---> 39\u001B[0m load_from_meta_list_into_db(\u001B[43mmeta_list\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'meta_list' is not defined"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree\n",
    "\n",
    "def load_single_article_text(canonical_url):\n",
    "    # for meta in meta_list:\n",
    "    url = f\"https://www.reuters.com{canonical_url}\"\n",
    "    \n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'Accept-Language': 'en-GB,en;q=0.9,en-US;q=0.8,de;q=0.7',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',\n",
    "        'Cookie': 'datadome=5DoGfdp_v7Y64hF3yeg8zmFRJvUZ_kY9APCBHhhY8Q5HnPWurio8XinFbT~guJr5RlIj0N41S2aQQNBEiMf05rg2Mb3BBC9zMM7Akw1aS8O9285Y~CC1YlyPQoYKfgLi; reuters-geo={\"country\":\"-\", \"region\":\"-\"}'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    \n",
    "    # get content in article\n",
    "    index_article_start = response.text.index(\"<article\")\n",
    "    index_article_end = response.text.index(\"</article>\")\n",
    "    article_text_html =  response.text[index_article_start:index_article_end+10]\n",
    "    \n",
    "    bs = BeautifulSoup(article_text_html, \"xml\")\n",
    "    \n",
    "    full_text = \"\"\n",
    "    \n",
    "    for EachPart in bs.select('div[class*=\"article-body__content__\"]'):\n",
    "        for paragraph in EachPart.parent.select('div[data-testid*=\"paragraph-\"]'):\n",
    "            full_text += \" \" + paragraph.text\n",
    "        \n",
    "    full_text = full_text.replace(\"\\n\",\"\")\n",
    "    \n",
    "    print(full_text)\n",
    "    \n",
    "# load_single_article_text(\"/business/aerospace-defense/us-preparing-new-weapons-package-ukraine-officials-2024-03-12/\")\n",
    "\n",
    "def load_from_meta_list_into_db(articles):\n",
    "    for article in articles:\n",
    "        load_single_article_text(article[\"canonical_url\"])\n",
    "\n",
    "load_from_meta_list_into_db(meta_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T19:05:34.334482Z",
     "start_time": "2024-03-12T19:05:34.309937Z"
    }
   },
   "id": "bb14cc9bf67d17d0",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "20022cae0d517351"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
