{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reuters Data fetch and save\n",
    "\n",
    "This notebook downloads all the data from the reuters about a specific topic and saves it to the database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0dcebd334270cc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import requests\n",
    "import math\n",
    "import ray\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T14:14:30.799848Z",
     "start_time": "2024-03-08T14:14:30.792680Z"
    }
   },
   "id": "4194653680e1e8be",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_PAGE_SIZE = 50\n",
    "REUTERS_QUERY_URL = 'https://www.reuters.com/pf/api/v3/content/fetch/articles-by-search-v2'\n",
    "PAGES_REQUESTS_SIZE = 10    # the amount of request ran in parallel to get pages faster, 10 pages loaded at the same time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T14:14:30.803669Z",
     "start_time": "2024-03-08T14:14:30.801841Z"
    }
   },
   "id": "c57473e637439ebb",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 15:40:33,142\tINFO worker.py:1540 -- Connecting to existing Ray cluster at address: 127.0.0.1:6379...\n",
      "2024-03-08 15:40:33,143\tINFO worker.py:1558 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query size is  5102\n",
      "total_page_size is  103\n",
      "pages_range is  12\n"
     ]
    },
    {
     "data": {
      "text/plain": "IntProgress(value=0, max=12)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c31d1e3023dc43248cfdf870f2ade9c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page 1 / 1250\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "Loading page 2 / 12500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "Loading page 3 / 12950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "Loading page 4 / 121400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "Loading page 5 / 121850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "Loading page 6 / 122300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "Loading page 7 / 122750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "Loading page 8 / 123200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "Loading page 9 / 123650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "Loading page 10 / 124100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "Loading page 11 / 124550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "Loading page 12 / 125000\n",
      "5050\n",
      "5100\n",
      "5150\n",
      "5200\n",
      "5250\n",
      "5300\n",
      "5350\n",
      "5400\n",
      "Error getting articles! {'statusCode': 400, 'result': None, '_id': 'c95c5ade6a77bb806de112e589fa2540cfe383543b2c63d08c9c7a1ff3cdc43f'}\n",
      "Error getting articles! {'statusCode': 400, 'result': None, '_id': 'c95c5ade6a77bb806de112e589fa2540cfe383543b2c63d08c9c7a1ff3cdc43f'}\n",
      "Error getting articles! {'statusCode': 400, 'result': None, '_id': 'c95c5ade6a77bb806de112e589fa2540cfe383543b2c63d08c9c7a1ff3cdc43f'}\n",
      "Error getting articles! {'statusCode': 400, 'result': None, '_id': 'c95c5ade6a77bb806de112e589fa2540cfe383543b2c63d08c9c7a1ff3cdc43f'}\n",
      "Error getting articles! {'statusCode': 400, 'result': None, '_id': 'c95c5ade6a77bb806de112e589fa2540cfe383543b2c63d08c9c7a1ff3cdc43f'}\n",
      "Error getting articles! {'statusCode': 400, 'result': None, '_id': 'c95c5ade6a77bb806de112e589fa2540cfe383543b2c63d08c9c7a1ff3cdc43f'}\n",
      "\n",
      " 5081\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "'''\n",
    "This functions queries reuters and gets the first few articles\n",
    "This query contains the \n",
    "'''\n",
    "\n",
    "num_cpus = 4\n",
    "    \n",
    "ray.init(ignore_reinit_error=True, num_cpus=num_cpus)\n",
    "\n",
    "def get_query_param(keyword, offset):\n",
    "    # print(offset)\n",
    "    \n",
    "    return {\n",
    "        \"query\": '{\"keyword\":\"%s\",\"offset\":%d,\"orderby\":\"display_date:desc\",\"size\":%d,\"website\":\"reuters\"}' % (keyword, offset, MAX_PAGE_SIZE),\n",
    "        \"d\": 179,\n",
    "        \"_website\": \"reuters\"\n",
    "    }\n",
    "\n",
    "def append_articles(articles_list, query_list):\n",
    "    requests_keys = [\"id\",\"canonical_url\",\"title\",\"published_time\"]\n",
    "\n",
    "    for query_articles in query_list:\n",
    "        articles_list.append({key: query_articles[key] for key in requests_keys})\n",
    "\n",
    "    return articles_list\n",
    "\n",
    "# resources = {\"requests_resource\": 1}, num_cpus=num_cpus\n",
    "@ray.remote\n",
    "def try_request(url, headers, params):\n",
    "        \n",
    "    response_page = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    try:\n",
    "        json_response = response_page.json()\n",
    "                \n",
    "        if response_page.status_code > 300:\n",
    "            print(\"Status code error: \" + str(response_page.status_code))\n",
    "            return False, None\n",
    "\n",
    "        return True, json_response\n",
    "    except requests.exceptions.JSONDecodeError as e:\n",
    "        print(f\"Bad Request: GET {url} \\n Status Code: {response_page.status_code} | Error : {e}\")\n",
    "        return False, None\n",
    "\n",
    "def query_reuters_news_meta(keyword):\n",
    "\n",
    "    # full query list\n",
    "    query_list = []\n",
    "\n",
    "    # build header. has just the cookie\n",
    "    headers = {\n",
    "        'Cookie': 'datadome=5DoGfdp_v7Y64hF3yeg8zmFRJvUZ_kY9APCBHhhY8Q5HnPWurio8XinFbT~guJr5RlIj0N41S2aQQNBEiMf05rg2Mb3BBC9zMM7Akw1aS8O9285Y~CC1YlyPQoYKfgLi; reuters-geo={\"country\":\"AT\", \"region\":\"-\"}'\n",
    "    }\n",
    "\n",
    "    # build the query params. \"query\" property must be a string of JSON, not an actual dict. must contain keyword and max page size\n",
    "    params = {\n",
    "        \"query\": '{\"keyword\":\"%s\",\"offset\":0,\"orderby\":\"display_date:desc\",\"size\":%d,\"website\":\"reuters\"}' % (keyword,MAX_PAGE_SIZE),\n",
    "        \"d\": 179,\n",
    "        \"_website\": \"reuters\"\n",
    "    }\n",
    "    \n",
    "    # make the first request\n",
    "    response_first = requests.request(\"GET\", REUTERS_QUERY_URL, headers=headers, params=params).json()\n",
    "    \n",
    "    # query_list.append({key: article[key] for key in requests_keys})\n",
    "\n",
    "    # print(\"Request done\")\n",
    "    # check if the request was valid by the given status code, else raise exception\n",
    "    if response_first['statusCode'] == 400:\n",
    "        raise Exception(f\"Bad Request: Query size of {MAX_PAGE_SIZE} is bigger than 100 with is not valid.\" )\n",
    "\n",
    "    # get pegination data and load all pages\n",
    "    query_result_total_size = response_first[\"result\"][\"pagination\"][\"total_size\"] \n",
    "    print(\"Query size is \", query_result_total_size)\n",
    "    \n",
    "    total_page_size = math.ceil(query_result_total_size / MAX_PAGE_SIZE)\n",
    "    \n",
    "    # print(\"total_page_size is \", total_page_size)\n",
    "\n",
    "    pages_range = math.ceil(total_page_size / PAGES_REQUESTS_SIZE) + 1\n",
    "\n",
    "    # print(\"pages_range is \", pages_range)\n",
    "    \n",
    "    f = IntProgress(min=0, max=pages_range) # instantiate the bar\n",
    "\n",
    "    # add first reponse to query list\n",
    "    query_list = append_articles(query_list, response_first[\"result\"][\"articles\"])\n",
    "\n",
    "    display(f) # display the bar\n",
    "    f.value += 1\n",
    "\n",
    "    #start at two and get all the messages available\n",
    "    # we will load 10 pages in parallel and  until we have all the pages.\n",
    "    last_offset = 0\n",
    "    \n",
    "    for i in range(1,pages_range+1):\n",
    "        print(\"\\rLoading page %d / %d\" % (i, pages_range), end=\"\")\n",
    "\n",
    "        tasks = []\n",
    "        for _ in range(1,PAGES_REQUESTS_SIZE):\n",
    "            offset = MAX_PAGE_SIZE + last_offset\n",
    "            tasks.append(\n",
    "                try_request.remote(\n",
    "                    REUTERS_QUERY_URL, \n",
    "                    params = get_query_param(keyword=keyword, offset=offset), \n",
    "                    headers = headers)\n",
    "            )\n",
    "            last_offset = offset\n",
    "        \n",
    "        results_list = ray.get(tasks)\n",
    "        \n",
    "        for (request_ok, json_parsed) in results_list:\n",
    "            if request_ok:\n",
    "                try:\n",
    "                    query_list = append_articles(query_list, json_parsed[\"result\"][\"articles\"])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error getting articles! {str(json_parsed)}\")\n",
    "                    pass\n",
    "            else:\n",
    "                print(f\"Error at task {last_offset}\")\n",
    "\n",
    "        f.value += 1\n",
    "\n",
    "    return query_list\n",
    "\n",
    "meta_list = query_reuters_news_meta(\"Tesla\")\n",
    "print(\"\\n Result Size: \", len(meta_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T14:40:44.614868Z",
     "start_time": "2024-03-08T14:40:33.102172Z"
    }
   },
   "id": "1c222d877add03eb",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bb14cc9bf67d17d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
