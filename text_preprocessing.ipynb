{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reuters Data Collection & Processing\n",
    "\n",
    "This notebook serve the purpose to fetch the data from the reuters webpage using their query api and crawling methods\n",
    "\n",
    "Disclaimer: Crawler is legal here. If the user can see the data without boting (login), then you can fetch it with normal requests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71bc7557e430f687"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f83e0ae0fe0a9fad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "import re\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e68ef8635b5b495f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Constant params "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a1fa951381c77a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_PAGE_SIZE = 100\n",
    "REUTERS_QUERY_URL = 'https://www.reuters.com/pf/api/v3/content/fetch/articles-by-search-v2'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c88daad598a6354d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get keywords related to a company.\n",
    "\n",
    "## Get entities from the text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6504fe1d00ab70f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)\n",
    "\n",
    "# used only for texting\n",
    "text_tesla = \"\"\"\n",
    "Tesla, Inc. is an American multinational automotive and clean energy company headquartered in Austin, Texas, which designs, manufactures and sells electric vehicles, stationary battery energy storage devices from home to grid-scale, solar panels and solar shingles, and related products and services.\n",
    "Tesla was incorporated in July 2003 by Martin Eberhard and Marc Tarpenning as Tesla Motors. The company's name is a tribute to inventor and electrical engineer Nikola Tesla. In February 2004 Elon Musk joined as the company's largest shareholder and in 2008 he was named CEO. In 2008, the company began production of its first car model, the Roadster sports car, followed by the Model S sedan in 2012, the Model X SUV in 2015, the Model 3 sedan in 2017, the Model Y crossover in 2020, the Tesla Semi truck in 2022 and the Cybertruck pickup truck in 2023. The Model 3 is the all-time bestselling plug-in electric car worldwide, and in June 2021 became the first electric car to sell 1 million units globally. In 2023, the Model Y was the best-selling vehicle, of any kind, globally.Tesla is one of the world's most valuable companies. In October 2021, Tesla's market capitalization temporarily reached $1 trillion, the sixth company to do so in U.S. history. As of 2023, it is the world's most valuable automaker. In 2022, the company led the battery electric vehicle market, with 18% share.\n",
    "Tesla has been the subject of lawsuits, government scrutiny, and journalistic criticism, stemming from allegations of whistleblower retaliation, worker rights violations, product defects, and Musk's many controversial statements.\n",
    "\"\"\"\n",
    "\n",
    "# convert the wordpiece into one\n",
    "def combine_bert_word_piece(doc, entities):    \n",
    "    for entity in entities:\n",
    "        if entity['word'].startswith(\"#\"):\n",
    "        \n",
    "            # find the entity before \n",
    "            before_entities = [*filter(lambda ent: ent[\"end\"] == entity[\"start\"], entities)]\n",
    "            \n",
    "            # if the port of the word is found\n",
    "            if len(before_entities) > 0:\n",
    "                # get the entity\n",
    "                before_entity = before_entities[0]\n",
    "                \n",
    "                # check if the combination exists in the text \n",
    "                combined = (before_entity[\"word\"] + entity[\"word\"].replace(\"##\",\"\"))\n",
    "                                \n",
    "                # if the combination exists in the document, get it \n",
    "                if combined in doc:\n",
    "                    # remove both entites which are not relevant for further processing\n",
    "                    entities = [*filter(lambda ent: ent[\"end\"] != entity[\"start\"] and entity[\"word\"] != ent[\"word\"],entities)]\n",
    "                    \n",
    "                    # replace it with a word relevant to the t'ext\n",
    "                    entity[\"word\"] = combined\n",
    "                    entities.append(entity)\n",
    "            else:       # if the part does not have a before part, remove it \n",
    "                entities = [*filter(lambda ent: entity['word'] != ent[\"word\"],entities)]\n",
    "                \n",
    "    return entities\n",
    "\n",
    "def remove_duplicates_entities(entities): \n",
    "    new_entities = []\n",
    "    for entity in entities:\n",
    "        word = entity[\"word\"]\n",
    "        if word not in new_entities:\n",
    "            new_entities.append(word)\n",
    "            \n",
    "    return new_entities\n",
    "\n",
    "# leave only the misc in the text\n",
    "ner_entities = nlp(text_tesla)\n",
    "# print(ner_entities)\n",
    "\n",
    "# combine the remaining bert word pieces if any are left out\n",
    "ner_entities = combine_bert_word_piece(text_tesla, ner_entities)\n",
    "\n",
    "# remove duplicates entities\n",
    "ner_entities = remove_duplicates_entities(ner_entities)\n",
    "\n",
    "print(ner_entities)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e5dec7e97152aef",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get keywords from the text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f4822a4bc6e1c74"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer_keyword = AutoTokenizer.from_pretrained(\"yanekyuk/bert-keyword-extractor\")\n",
    "model_keyword = AutoModelForTokenClassification.from_pretrained(\"yanekyuk/bert-keyword-extractor\")\n",
    "\n",
    "nlp_keyword = pipeline(\"token-classification\", model=model_keyword, tokenizer=tokenizer_keyword, grouped_entities=True)\n",
    " \n",
    "# get all keywords from the text\n",
    "    \n",
    "def complete_incomplete_keywords(keywords, doc):\n",
    "    \n",
    "    new_keywords_array = []\n",
    "    for keyword in keywords:\n",
    "        # first detect if keyword is part of a whole word.\n",
    "        patter_whole_word = rf\"[,.;\\\"'\\/\\\\\\s]({keyword})[,.;\\\"'\\/\\\\\\s]\"\n",
    "        is_whole_word = bool(re.search(patter_whole_word, doc))\n",
    "            \n",
    "        # if is part of a complete word, append, else complete the word\n",
    "        if is_whole_word:\n",
    "            new_keywords_array.append(keyword)\n",
    "        else:\n",
    "            if keyword in doc:\n",
    "                pat_in_word = rf\"(?<=[,.;\\\"'\\/\\\\\\s])(\\w*){keyword}(\\w*)(?=[,.;\\\"'\\/\\\\\\s])\"\n",
    "                match = re.search(pat_in_word,doc)\n",
    "            \n",
    "                if match is not None:\n",
    "                    new_full_key_word = f\"{match.groups(1)[0]}{keyword}{match.groups(1)[1]}\"\n",
    "                    # print(f\"Keyword inside a full word found: {match.groups(1)[0]}{keyword}{match.groups(1)[1]}\")\n",
    "                    new_keywords_array.append(new_full_key_word)\n",
    "            else:\n",
    "                #TODO: match words with space a special character after\n",
    "                special_char_keyword = keyword.replace(\" \", \"\")\n",
    "                if special_char_keyword in doc:\n",
    "                    pat_in_word = rf\"(?<=[,.;\\\"'\\/\\\\\\s])(\\w*){special_char_keyword}(\\w*)(?=[,.;\\\"'\\/\\\\\\s])\"\n",
    "                    match = re.search(pat_in_word,doc)\n",
    "                \n",
    "                    if match is not None:\n",
    "                        new_full_key_word = f\"{match.groups(1)[0]}{special_char_keyword}{match.groups(1)[1]}\"\n",
    "                        # print(f\"Keyword inside a special character: {match.groups(1)[0]}{special_char_keyword}{match.groups(1)[1]}\")\n",
    "                        new_keywords_array.append(new_full_key_word)\n",
    "                else: \n",
    "                    print(\"Invalid keyword: \", special_char_keyword)\n",
    "               \n",
    "    return new_keywords_array\n",
    "\n",
    "# join with entities list\n",
    "def join_key_token_lists(token_list_a, token_list_b):\n",
    "    for keyword in token_list_a:\n",
    "        if keyword not in token_list_b:\n",
    "            token_list_b.append(keyword)\n",
    "\n",
    "    return token_list_b\n",
    "\n",
    "def get_keywords_from_text(txt):\n",
    "    res = combine_bert_word_piece(text_tesla,nlp_keyword(txt))\n",
    "    res = [*map(lambda k_word: k_word[\"word\"], res)]\n",
    "    return res\n",
    "\n",
    "def remove_invalid_keywords(keywords):    \n",
    "    return list(filter(lambda k_word: not bool(re.search(rf\"^[-,;.:\\\"'\\/\\\\\\s]*$\",k_word)), keywords))\n",
    "\n",
    "keyword_result = get_keywords_from_text(text_tesla)\n",
    "\n",
    "key_tokens = ner_entities.copy()\n",
    "\n",
    "keyword_result = join_key_token_lists(keyword_result,key_tokens)\n",
    "keyword_result = complete_incomplete_keywords(keyword_result, text_tesla)\n",
    "\n",
    "print(keyword_result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6d03ab3628f1aac",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Function to extract from wikipedia page"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "277691783cf67139"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_wikipedia_sections(wikipedia):\n",
    "    sections_content = wikipedia_sections(wikipedia.sections, 0, [] , {})    \n",
    "    sections_content[\"main\"] = wikipedia.summary\n",
    "    return sections_content\n",
    "\n",
    "def get_wikipedia_full_page(wikipedia):\n",
    "    sections_content = wikipedia_sections(wikipedia.sections, 0, [] , {})\n",
    "    text_full = []\n",
    "    for section in sections_content:\n",
    "        text_full.append(sections_content[section])\n",
    "    return text_full\n",
    "\n",
    "def wikipedia_sections(sections, level, sections_list, out):\n",
    "    # get all the sections \n",
    "    for s in sections:\n",
    "        if s.title not in out:\n",
    "            out[s.title] = s.text\n",
    "        \n",
    "        wikipedia_sections(s.sections, level + 1, sections_list, out)\n",
    "        \n",
    "    return out\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29e3f68a64439105",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_duplicate_keywords(keywords):\n",
    "    new_keywords = []\n",
    "    for keyword in keywords:\n",
    "        if keyword not in new_keywords:\n",
    "            new_keywords.append(keyword)\n",
    "\n",
    "    return new_keywords\n",
    "\n",
    "def get_wikipedia_page(name):\n",
    "    # get wikipedia page content\n",
    "    wiki_page = wikipediaapi.Wikipedia('Sebastian Tatar (sebi.tatar2@gmail.com)', 'en')\n",
    "    return wiki_page.page(name)\n",
    "\n",
    "# get keywords from wikipedia page\n",
    "def get_relevant_words_from_company(name):\n",
    "    \n",
    "    # get wikipedia page content\n",
    "    wiki_page = get_wikipedia_page(name)\n",
    "   \n",
    "    sections = get_wikipedia_sections(wiki_page)\n",
    "    section_main = sections[\"main\"]\n",
    "            \n",
    "    # get the name entity\n",
    "    named_entities = nlp(section_main)\n",
    "    # combine the remaining bert word pieces if any are left out\n",
    "    named_entities = combine_bert_word_piece(section_main, named_entities)\n",
    "    \n",
    "    # remove duplicates entities\n",
    "    named_entities = remove_duplicates_entities(named_entities)\n",
    "    named_entities = complete_incomplete_keywords(named_entities, section_main)\n",
    "\n",
    "    # get company keywords\n",
    "    keywords = get_keywords_from_text(section_main)\n",
    "    #print(keywords)\n",
    "    keywords = remove_duplicate_keywords(keywords)\n",
    "    keywords = complete_incomplete_keywords(keywords, section_main)\n",
    "    keywords = remove_invalid_keywords(keywords)\n",
    "    \n",
    "    print(keywords)\n",
    "\n",
    "    # TODO: Topic Modeling\n",
    " \n",
    "    return {\n",
    "        \"entities\": named_entities,\n",
    "        \"keywords\": keywords,\n",
    "        \"topics\":[],\n",
    "        \"combined\": join_key_token_lists(named_entities,keywords),\n",
    "    }\n",
    "\n",
    "keywords_tesla = get_relevant_words_from_company(\"Tesla, Inc.\")\n",
    "keywords_nvidia = get_relevant_words_from_company(\"Nvidia\")\n",
    "#keywords_microsoft = get_relevant_words_from_company(\"Microsoft\")\n",
    "#keywords_proctor_gamble = get_relevant_words_from_company(\"Procter & Gamble\")\n",
    "#keywords_coca_cola = get_relevant_words_from_company(\"Coca-Cola\")\n",
    "\n",
    "# print(keywords_tesla)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72c786ba7de2cd48",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "keywords_tfidf = keywords_tesla.copy()\n",
    "\n",
    "\n",
    "def find_num_occurrences(word, string):\n",
    "    return string.lower().count(word.lower())\n",
    "\n",
    "def get_keywords_weight_from_corpus(corpus, keywords):\n",
    "    \n",
    "    words_weight_arr = {}\n",
    "    for word in keywords:\n",
    "        word_count = 0\n",
    "        for corp in corpus:\n",
    "            sum_in_line = find_num_occurrences(word, corp)\n",
    "            word_count = word_count + sum_in_line\n",
    "            # print(word_count)\n",
    "\n",
    "        if word in words_weight_arr:\n",
    "            words_weight_arr[word] = words_weight_arr[word] + word_count\n",
    "        else:\n",
    "            words_weight_arr[word] = word_count\n",
    "    \n",
    "    key_arr = list(words_weight_arr.keys())\n",
    "    values_arr = list(words_weight_arr.values())\n",
    "    values_arr = preprocessing.normalize([np.array(values_arr)])[0].tolist()\n",
    "\n",
    "    words_weight_arr = {key_arr[i]: values_arr[i] for i in range(len(key_arr))}\n",
    "\n",
    "    return sorted(words_weight_arr.items(), key=lambda item: item[1])\n",
    "    \n",
    "wiki_page_tesla = get_wikipedia_page(\"Tesla, Inc.\")\n",
    "corpus_tesla = get_wikipedia_full_page(wiki_page_tesla)[1:] # first is empty\n",
    "\n",
    "words_weights = get_keywords_weight_from_corpus(corpus_tesla, keywords_tesla['combined'])\n",
    "\n",
    "for words_weight in words_weights:\n",
    "    print(words_weight)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc3ce62b092e57e4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d23839dedaefdb8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reference_title = \"Elon Musk's Tesla overhaul hits executive bench he touted\"\n",
    "\n",
    "reference_text = 'May 1 (Reuters) - Just over a year ago, Elon Musk shared the stage at Tesla\\'s (TSLA.O), opens new tab investor day in Texas with 16 executives who gave detailed presentations on the company\\'s technology and growth plans, then lined up behind their boss in a show of solidarity.,\\\"We\\'ve obviously got significant bench strength here,\" Musk said at the time, responding to investor concerns that the world\\'s most valuable automaker was too much a one-man show. Now, at least five members of that team are gone, a Reuters analysis shows. Tesla, Musk and the 16 executives on the stage last year could not be reached for comment. Musk in a recent email to senior managers outlined plans to lay off hundreds more employees, including two top executives, the Information reported. \"Hopefully these actions are making it clear that we need to be absolutely hard core about headcount and cost reduction,\" Musk wrote in the email, the report said. Two senior executives who flanked Musk on investor day last year are gone: Zach Kirkhorn, former CFO, resigned with a nondisclosure agreement, according to Tesla regulatory filings. Drew Baglino, Tesla\\'s former chief battery engineer, left in the wave of layoffs Musk ordered last month. Baglino dumped $181 million in Tesla stock as he left. Rebecca Tinucci, who headed up Tesla\\'s charging team, was one of two women on stage for the investor day last March. \"We have understood since Day One that a great charging experience is the linchpin to electric vehicle adoption,\" Tinucci said as she walked onstage. In the subsequent year, nearly all rival automakers in the United States agreed to adopt Tesla\\'s charging standards and cut deals to let their EV buyers charge at Tesla stations. Tinucci and much of her team were sacked this week. In a posting on his social media platform X, Musk said Tesla plans \"to grow the Supercharger network, just at a slower pace for new locations and more focus on 100% uptime and expansion of existing locations.\" Another executive on the stage who left was Colin Campbell, the former vice president of powertrain engineering. The loss of so many executives is something the Tesla board should be monitoring, said Charles Elson, founding director of the Weinberg Center for Corporate Governance at the University of Delaware. \"Lots of departures very quickly suggest a problematic leadership style,\" he said. \"You shouldn\\'t lose that many people that quickly.\" With Tesla\\'s revenue, profit and share price falling, Musk has reasserted his dominance at the company. For some investors, that is more important than the executive churn. \"Elon\\'s not there and we have this turnover? That\\'s very bad,\" said Gene Munster, managing partner with Deepwater Asset Management and a Tesla investor. \"If Elon\\'s there, he\\'s going to draw on talent to keep things going so it really all comes down to Elon remaining a part of the story.\" Musk has signaled significant strategy shifts in response to falling sales and tougher competition - changes that could leave out executives running operations no longer central to the new plans. Tesla\\'s future lies in artificial intelligence and robotaxis, not conventional auto manufacturing, Musk told investors in April. Musk is putting action behind those words. He has ordered a 10% cut in staff and scrapped plans for a new, low-cost line of vehicles in favor of revamping existing models to develop lower-priced entries. Tesla said it will pause construction of new factories until the company\\'s sales had reached 3 million vehicles a year - enough to fill up the automaker\\'s existing production operations. \"If you buy the narrative that Tesla is an AI company fundamentally, it may not be cause for concern,\" said K.C. Boyce, vice president at data analytics and advisory firm Escalent. \"It fits into the idea of sizing and resourcing the business correctly to deliver on the promise of full self-driving and robotaxi.\" Other senior Tesla executives, who were not among those onstage during the 2023 investor day, have left in recent weeks. Daniel Ho, a former Ford executive and 10-year Tesla veteran who had been director of new car programs, is no longer with the company. Rohan Patel, a former Obama administration official who had been Tesla VP for public policy and key to expansion plans for India, said he is leaving. Another executive to exit was Allie Arebalo, Tesla\\'s senior director of human resources, two people familiar with the matter said on Wednesday. Martin Viecha, head of investor relations who also was on the stage last year with Musk, announced his departure at the end of an April 24 conference call with analysts. Unlike most of the other departed executives, Viecha received a warm sendoff from Musk. \"The reason I reached out to you was because I thought your analysis of Tesla was the best that I had seen,\" Musk said on the call. Some analysts said the executive team is critical given the challenges faced by the EV maker. \"Having a strong bench behind Musk is important at this pivotal time given the Category 5 storm that Tesla\\'s going through,\" Wedbush Securities analyst Dan Ives said.'\n",
    "\n",
    "def calculate_text_relevance(title, text, keywords_weighted):\n",
    "    relevance_score = 0\n",
    "    for keyword in keywords_weighted:\n",
    "        keyword_count = text.count(keyword[0])\n",
    "        relevance_score += keyword_count * keyword[1]\n",
    "    return relevance_score\n",
    "        \n",
    "calculate_text_relevance(reference_title, reference_text, words_weights)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35f7b174b160ca36",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis for Text\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3a6feadee6fa626"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import scipy\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "tokenizer.model_max_length = 2540\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "\n",
    "reference_text_small = 'Just over a year ago, Elon Musk shared the stage at Tesla\\'s (TSLA.O), opens new tab investor day in Texas with 16 executives who gave detailed presentations on the company\\'s technology and growth plans, then lined up behind their boss in a show of solidarity.,\\\"We\\'ve obviously got significant bench strength here,\" Musk said at the time, responding to investor concerns that the world\\'s most valuable automaker was too much a one-man show. Now, at least five members of that team are gone, a Reuters analysis shows. Tesla, Musk and the 16 executives on the stage last year could not be reached for comment. Musk in a recent email to senior managers outlined plans to lay off hundreds more employees, including two top executives, the Information reported. \"Hopefully these actions are making it clear that we need to be absolutely hard core about headcount and cost reduction,\" Musk wrote in the email, the report said. Two senior executives who flanked Musk on investor day last year are gone: Zach Kirkhorn, former CFO, resigned with a nondisclosure agreement, according to Tesla regulatory filings. Drew Baglino, Tesla\\'s former chief battery engineer, left in the wave of layoffs Musk ordered last month. Baglino dumped $181 million in Tesla stock as he left. Rebecca Tinucci, who headed up Tesla\\'s charging team, was one of two women on stage for the investor day last March. \"We have understood since Day One that a great charging experience is the linchpin to electric vehicle adoption,\" Tinucci said as she walked onstage. '"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bc21372dac9e027",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2aaa31dcfc8ac3c9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0.18652974384335372, 'negative': 0.4256132437537114, 'neutral': 0.38785701694014746}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# Needed this code to get the sentiment score:\n",
    "# https://datascience.stackexchange.com/a/112446\n",
    "async def get_sentiment_score_text(text, sentiment_score: list):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    scores = {k: v for k, v in zip(model.config.id2label.values(), scipy.special.softmax(logits.numpy().squeeze()))}\n",
    "\n",
    "    sentiment_score.append(scores)\n",
    "\n",
    "    return scores\n",
    "\n",
    "async def get_sentiment_score_large_text(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    task_list = []\n",
    "    \n",
    "    sentiment_scores = []   \n",
    "        \n",
    "    for sentence in sentences:\n",
    "        task_list.append(asyncio.create_task(get_sentiment_score_text(sentence, sentiment_scores)))\n",
    "        # sentiment_scores.append(sentence_score)\n",
    "\n",
    "    await asyncio.gather(*task_list)\n",
    "        \n",
    "    # Average the sentiment scores\n",
    "    avg_sentiment_score = {k: sum(d[k] for d in sentiment_scores)/len(sentiment_scores) for k in sentiment_scores[0]}\n",
    "\n",
    "    return avg_sentiment_score\n",
    "\n",
    "sentiment_score = await get_sentiment_score_large_text(reference_text)\n",
    "\n",
    "print(sentiment_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T18:35:02.086606Z",
     "start_time": "2024-05-14T18:34:47.762135Z"
    }
   },
   "id": "6690aeaa2f72ed03",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "94d8d73f9600eb82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
